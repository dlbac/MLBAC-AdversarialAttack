{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQOsBlPEGBDa"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz1P0301GBDb"
      },
      "outputs": [],
      "source": [
        "# Misc\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-l2D4ElGBDd"
      },
      "outputs": [],
      "source": [
        "# Sklearn\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLP7XUYOGBDe"
      },
      "outputs": [],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data preprocessing"
      ],
      "metadata": {
        "id": "c6i5MQOLJXBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import importlib\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.backends.cudnn\n",
        "import torchvision.utils\n",
        "\n",
        "from dataloader import get_loader\n",
        "\n",
        "from numpy import loadtxt\n",
        "\n",
        "from os import path\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='[%(asctime)s %(name)s %(levelname)s] - %(message)s',\n",
        "    datefmt='%Y/%m/%d %H:%M:%S',\n",
        "    level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "debug = False\n",
        "\n",
        "def str2bool(s):\n",
        "    if s.lower() == 'true':\n",
        "        return True\n",
        "    elif s.lower() == 'false':\n",
        "        return False\n",
        "    else:\n",
        "        raise RuntimeError('Boolean value expected')\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "\n",
        "    model_config = OrderedDict([\n",
        "        ('arch', 'resnet'),\n",
        "        ('block_type', 'basic'),\n",
        "        ('depth', 8), # depth=8 for ResNet8, and depth=50 for ResNet50\n",
        "        ('base_channels', 16),\n",
        "        ('input_shape', (1, 3, 32, 32)),\n",
        "        ('n_classes', 1),\n",
        "    ])\n",
        "\n",
        "    optim_config = OrderedDict([\n",
        "        ('epochs', 5),\n",
        "        ('batch_size', 16), #we also use this number for the evaluation\n",
        "        ('base_lr', 1e-3),\n",
        "        ('weight_decay', 1e-4),\n",
        "        ('milestones', json.loads('[10, 20, 25]')),\n",
        "        ('lr_decay', 0.1),\n",
        "    ])\n",
        "\n",
        "    run_config = OrderedDict([\n",
        "        ('seed', 17),\n",
        "        ('outdir', 'result'),\n",
        "        ('networkdir', 'neural_network'),\n",
        "        ('debug', True),\n",
        "    ])\n",
        "\n",
        "    config = OrderedDict([\n",
        "        ('model_config', model_config),\n",
        "        ('optim_config', optim_config),\n",
        "        ('run_config', run_config),\n",
        "    ])\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def load_model(config):\n",
        "    module = importlib.import_module(config['arch'])\n",
        "    Network = getattr(module, 'Network')\n",
        "    return Network(config)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, num):\n",
        "        self.val = val\n",
        "        self.sum += val * num\n",
        "        self.count += num\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def data_parser():\n",
        "\n",
        "    # Load data\n",
        "    dataFileName = '/content/u5k-r5k-auth12k.sample'\n",
        "    meta_data = 0\n",
        "    cols = 22\n",
        "    ########### CONFIG END ###################\n",
        "\n",
        "    # load the dataset\n",
        "    raw_dataset = loadtxt(dataFileName, delimiter=' ', dtype=str)\n",
        "    dataset = raw_dataset[:,2:cols] # TO SKIP UID RID\n",
        "    #np.random.shuffle(dataset)\n",
        "\n",
        "    # split into user-resource pair and operations variables\n",
        "    feature = dataset.shape[1]\n",
        "    attribs = feature - 4\n",
        "\n",
        "    continuous_data = dataset[:,0:attribs - 8] # assume first eight attributes are continuous\n",
        "    categorical_data = dataset[:,8:attribs] # assume second eight attributes are categorical\n",
        "    target_data = dataset[:, 16] # target label -- permit or deny\n",
        "    metadata_target = dataset[:, 0:attribs + 1] #(all metadata and one operation)\n",
        "\n",
        "    categorical_encoded = to_categorical(categorical_data)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(continuous_data)    \n",
        "    continuous_data = scaler.transform(continuous_data)\n",
        "\n",
        "    continuous_data= continuous_data[..., np.newaxis]\n",
        "    combined_data = np.concatenate((categorical_encoded, continuous_data), axis=2)\n",
        "\n",
        "    #determine evaluation dataset size\n",
        "    eval_size = (int)(combined_data.shape[0] * 0.20) #20% of total dataset\n",
        "\n",
        "    X_Test = combined_data[:eval_size,:]\n",
        "    Y_Test = target_data[:eval_size]\n",
        "    X_Train = combined_data[eval_size:,:]\n",
        "    Y_Train = target_data[eval_size:]\n",
        "\n",
        "    return X_Train, X_Test, Y_Train, Y_Test, metadata_target\n"
      ],
      "metadata": {
        "id": "aVbX2WeVISPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training and Testing Methods"
      ],
      "metadata": {
        "id": "kUJ4XxCTIgG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch, model, optimizer, criterion, train_loader, run_config):\n",
        "    global global_step\n",
        "\n",
        "    logger.info('Train {}'.format(epoch))\n",
        "\n",
        "    model = model.double()\n",
        "    model.train()\n",
        "\n",
        "    start = time.time()\n",
        "    for step, (data, targets) in enumerate(train_loader):\n",
        "        global_step += 1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        targets = targets.double()\n",
        "        targets = targets.unsqueeze(1)\n",
        "        outputs = model(data.double())\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            logger.info('Epoch {} Step {}/{}'.format(\n",
        "                            epoch,\n",
        "                            step,\n",
        "                            len(train_loader)\n",
        "                        ))\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    logger.info('Elapsed {:.2f}'.format(elapsed))\n",
        "\n",
        "\n",
        "def test(epoch, model, criterion, test_loader, run_config):\n",
        "    logger.info('Test {}'.format(epoch))\n",
        "    model = model.double()\n",
        "    model.eval()\n",
        "\n",
        "    start = time.time()\n",
        "    for step, (data, targets) in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(data.double())\n",
        "        \n",
        "        targets = targets.double()\n",
        "        targets = targets.unsqueeze(1)\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    logger.info('Elapsed {:.2f}'.format(elapsed))\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "Q0JNcz4VIfhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training ResNet"
      ],
      "metadata": {
        "id": "F30BeNYPRBWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # parse arguments\n",
        "    config = parse_args()\n",
        "\n",
        "    run_config = config['run_config']\n",
        "    optim_config = config['optim_config']\n",
        "    debug = run_config['debug']\n",
        "\n",
        "    # set random seed\n",
        "    seed = run_config['seed']\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # create output directory\n",
        "    outdir = run_config['outdir']\n",
        "    if not os.path.exists(outdir):\n",
        "        os.makedirs(outdir)\n",
        "\n",
        "    # create neural_network directory\n",
        "    networkdir = run_config['networkdir']\n",
        "    if not os.path.exists(networkdir):\n",
        "        os.makedirs(networkdir)\n",
        "\n",
        "    # save config as json file in output directory\n",
        "    outpath = os.path.join(outdir, 'config.json')\n",
        "    with open(outpath, 'w') as fout:\n",
        "        json.dump(config, fout, indent=2)\n",
        "\n",
        "    x_train, x_test, y_train, y_test, metadata_target = data_parser()\n",
        "    if debug:\n",
        "        print('x_train shape after return:', x_train.shape)\n",
        "        print('y_train shape after return:', y_train.shape)\n",
        "   \n",
        "    model_config = config['model_config']\n",
        "    if debug:\n",
        "        print('before assigning, default input shape', model_config['input_shape'])\n",
        "    \n",
        "    input_shape = x_train[0].reshape((1,1,)+x_train[0].shape)\n",
        "    model_config['input_shape'] = input_shape.shape\n",
        "    if debug:\n",
        "        print('model config input shape', model_config['input_shape'])\n",
        "\n",
        "    train_loader, test_loader = get_loader(optim_config['batch_size'],\n",
        "                                           x_train, x_test, y_train, y_test)\n",
        "\n",
        "    if debug:\n",
        "        print('train_loader len', len(train_loader), 'test_loader', len(test_loader))\n",
        "    \n",
        "    model = load_model(config['model_config'])\n",
        "    n_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
        "    logger.info('n_params: {}'.format(n_params))\n",
        "\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=optim_config['base_lr'])\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=optim_config['milestones'],\n",
        "        gamma=optim_config['lr_decay'])\n",
        "\n",
        "    test(0, model, criterion, test_loader, run_config)\n",
        "\n",
        "    for epoch in range(1, optim_config['epochs'] + 1):\n",
        "        model = model.float()\n",
        "        train(epoch, model, optimizer, criterion, train_loader, run_config)\n",
        "        scheduler.step()\n",
        "        test(epoch, model, criterion, test_loader, run_config)\n",
        "\n",
        "        state = OrderedDict([\n",
        "            ('config', config),\n",
        "            ('state_dict', model.state_dict()),\n",
        "            ('optimizer', optimizer.state_dict()),\n",
        "            ('epoch', epoch),\n",
        "            #('accuracy', accuracy),\n",
        "        ])\n",
        "        model_path = os.path.join(networkdir, 'mlbac_model.pth')\n",
        "        torch.save(state, model_path)\n",
        "    \n",
        "    print('End of model training. Trained model exported to: ', model_path)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "QUss8_76RA-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train ML model from scratch. If the model is trained once, **no need** to retrain further. We load the trained model for the adversarial attack simulation"
      ],
      "metadata": {
        "id": "saoaL_Q8z_GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "drgsO19ySLDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJKIsfXbGBDm"
      },
      "source": [
        "### Generate adversarial examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = True\n",
        "def train_load_save_model(model_obj, model_path):\n",
        "    if path.isfile(model_path):\n",
        "        if debug:\n",
        "            print('Loading pre-trained model from: {}'.format(model_path))\n",
        "        checkpoint = torch.load(model_path)\n",
        "        model_obj.load_state_dict(checkpoint['state_dict'])\n",
        "        if debug:\n",
        "            print('model loading successful!')\n",
        "\n",
        "\n",
        "def restore_trained_model_data():\n",
        "    # parse arguments\n",
        "    config = parse_args()\n",
        "\n",
        "    run_config = config['run_config']\n",
        "    optim_config = config['optim_config']\n",
        "    debug = run_config['debug']\n",
        "    debug = False\n",
        "\n",
        "    # set random seed\n",
        "    seed = run_config['seed']\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # create output directory\n",
        "    outdir = run_config['outdir']\n",
        "    if not os.path.exists(outdir):\n",
        "        os.makedirs(outdir)\n",
        "\n",
        "    # save config as json file in output directory\n",
        "    outpath = os.path.join(outdir, 'config.json')\n",
        "    with open(outpath, 'w') as fout:\n",
        "        json.dump(config, fout, indent=2)\n",
        "\n",
        "    x_train, x_test, y_train, y_test, metadata_target = data_parser()\n",
        "    if debug:\n",
        "        print('x_train shape after return:', x_train.shape)\n",
        "        print('y_train shape after return:', y_train.shape)\n",
        "   \n",
        "    model_config = config['model_config']\n",
        "    if debug:\n",
        "        print('before assigning, default input shape', model_config['input_shape'])\n",
        "    \n",
        "    input_shape = x_train[0].reshape((1,1,)+x_train[0].shape)\n",
        "    model_config['input_shape'] = input_shape.shape\n",
        "    if debug:\n",
        "        print('model config input shape', model_config['input_shape'])\n",
        "\n",
        "    train_loader, test_loader = get_loader(optim_config['batch_size'],\n",
        "                                           x_train, x_test, y_train, y_test)\n",
        "\n",
        "    if debug:\n",
        "        print('train_loader len', len(train_loader), 'test_loader', len(test_loader))\n",
        "    \n",
        "    model = load_model(config['model_config'])\n",
        "    n_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
        "    logger.info('n_params: {}'.format(n_params))\n",
        "\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=optim_config['base_lr'])\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=optim_config['milestones'],\n",
        "        gamma=optim_config['lr_decay'])\n",
        "    \n",
        "    model_path = os.path.join('neural_network', 'mlbac_model.pth')\n",
        "    train_load_save_model(model, model_path)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader_iterator = iter(test_loader)\n",
        "    testdata, targets = next(dataloader_iterator)\n",
        "\n",
        "    return metadata_target, testdata, targets, model"
      ],
      "metadata": {
        "id": "QvOfB71vvdRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Determine Accessibility Constraint in terms of security levels**"
      ],
      "metadata": {
        "id": "OGeIju_cZLWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_security_levels(metadatadata_target):\n",
        "  print(metadata_target.shape)\n",
        "  target = 'access'\n",
        "  feature_names = ['umeta0','umeta1','umeta2','umeta3','rmeta0','rmeta1','rmeta2','rmeta3','umeta4','umeta5','umeta6','umeta7','rmeta4','rmeta5','rmeta6','rmeta7']\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler.fit(metadata_target)    \n",
        "  df_norm = scaler.transform(metadata_target)\n",
        "\n",
        "  df = pd.DataFrame(df_norm, columns = feature_names + [target])\n",
        "  cor = df.corr()\n",
        "  cor_target = abs(cor[target])\n",
        "  print('correlation with respect to target is successful!')\n",
        "\n",
        "  security_levels = cor_target[:-1]\n",
        "  security_levels = security_levels / np.linalg.norm(security_levels)\n",
        "          \n",
        "  return security_levels.values"
      ],
      "metadata": {
        "id": "OtNcS-4jZQcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accessibility_constraint(security_levels, rows, cols):\n",
        "  sec_levels_matrix = np.ones((rows, cols), dtype=float)\n",
        "\n",
        "  data_type_wise_levels = np.split(security_levels, 2)\n",
        "  continuous_sec_levels = data_type_wise_levels[0]\n",
        "  categorical_sec_levels = data_type_wise_levels[1]\n",
        "\n",
        "  for col in range(cols - 1):\n",
        "    sec_levels_matrix[: , col] = categorical_sec_levels\n",
        "\n",
        "  sec_levels_matrix[:, cols - 1] = continuous_sec_levels\n",
        "\n",
        "  return sec_levels_matrix"
      ],
      "metadata": {
        "id": "_Eq-nFNaIqfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load** the **trained model** for the adversarial attack simulation. Also, generate **accessibility constraint**"
      ],
      "metadata": {
        "id": "MSGQnDXy0S4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_target, testdata, targets, model = restore_trained_model_data()\n",
        "model = model.double()\n",
        "\n",
        "sec_levels = get_security_levels(metadata_target)\n",
        "\n",
        "r = int(testdata[0].shape[1])\n",
        "c = int(testdata[0].shape[2])\n",
        "accessibility_constraint = get_accessibility_constraint(sec_levels, r, c)\n"
      ],
      "metadata": {
        "id": "oSM0-QRqg0-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluate the adversarial attack performance***\n",
        "\n",
        "For the **number of samples** for an evaluation, we change the \"**batch_size**\" in configuration, e.g. to test for 200 samples count, we set batch_size=200"
      ],
      "metadata": {
        "id": "Nl81w37MqYIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import CustomLowProFool approach\n",
        "from CustomLowProFool import lowProFoolWithAccessibilityConstraint, lowProFoolWithNoAccessibilityConstraint\n",
        "\n",
        "successful_adv = 0\n",
        "success_deny = 0\n",
        "success_grant = 0\n",
        "fail_deny = 0\n",
        "fail_grant = 0\n",
        "\n",
        "maxiters = 25\n",
        "alpha = 0.2\n",
        "omega = 6.0\n",
        "\n",
        "print('Evaluating for sample count: ', testdata.shape[0])\n",
        "\n",
        "for row in range(testdata.shape[0]):\n",
        "    data = testdata[row]\n",
        "    data = data.double()\n",
        "    x_tensor = data.reshape((1,)+data.shape)\n",
        "    \n",
        "    orig_pred, adv_pred, x_adv = lowProFoolWithAccessibilityConstraint(x_tensor, model, accessibility_constraint, maxiters, alpha, omega)\n",
        "    #orig_pred, adv_pred, x_adv = lowProFoolWithNoAccessibilityConstraint(x_tensor, model, maxiters, alpha, omega)\n",
        "    if orig_pred != adv_pred:\n",
        "      successful_adv += 1\n",
        "    target_pred = np.abs(1 - orig_pred)\n",
        "    \n",
        "    if target_pred == 0.0 and adv_pred == target_pred:\n",
        "      success_deny += 1\n",
        "    elif target_pred == 1.0 and adv_pred == target_pred:\n",
        "      success_grant += 1\n",
        "    elif target_pred == 0.0 and adv_pred != target_pred:\n",
        "      fail_deny += 1\n",
        "    elif target_pred == 1.0 and adv_pred != target_pred:\n",
        "      fail_grant += 1\n",
        "\n",
        "print('successful adversarial samples: ', successful_adv)\n",
        "print('Success Rate', successful_adv/ testdata.shape[0])\n",
        "#print('succss_deny', success_deny, 'success_grant', success_grant, 'fail_deny', fail_deny, 'fail_grant', fail_grant)\n"
      ],
      "metadata": {
        "id": "d8InT_8GyAv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456ddce0-3fab-4da4-e432-f04a019e5203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating for sample count:  16\n",
            "successful adversarial samples:  12\n",
            "Success Rate 0.75\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "int",
      "language": "python",
      "name": "int"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "MLBACAdversarialAttackSimilation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}